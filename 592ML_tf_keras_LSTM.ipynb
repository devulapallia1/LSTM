{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devulapallia1/LSTM/blob/main/592ML_tf_keras_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0pRH3IrWVxE"
      },
      "outputs": [],
      "source": [
        "# reference: www.tensorflow.org/text/tutorials/text_classification_rnn\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "tfds.disable_progress_bar() # disable the display status of a determinate or indeterminate process\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCeLQIoUNJu0",
        "outputId": "3b881292-34ee-4947-c6d8-198ae7b11bf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0...\n",
            "Dataset imdb_reviews downloaded and prepared to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(), dtype=tf.string, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.int64, name=None))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# each review has either a positive (1) or negative (0) sentiment\n",
        "\n",
        "dataset, info = tfds.load('imdb_reviews', with_info=True,\n",
        "                          as_supervised=True)\n",
        "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
        "\n",
        "train_dataset.element_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnwDc55dNqfb",
        "outputId": "b757ac49-7d73-445c-bb36-9657feeafc3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "text:  b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\"\n",
            "label:  0\n",
            "text:  b'I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However on this occasion I fell asleep because the film was rubbish. The plot development was constant. Constantly slow and boring. Things seemed to happen, but with no explanation of what was causing them or why. I admit, I may have missed part of the film, but i watched the majority of it and everything just seemed to happen of its own accord without any real concern for anything else. I cant recommend this film at all.'\n",
            "label:  0\n",
            "text:  b'Mann photographs the Alberta Rocky Mountains in a superb fashion, and Jimmy Stewart and Walter Brennan give enjoyable performances as they always seem to do. <br /><br />But come on Hollywood - a Mountie telling the people of Dawson City, Yukon to elect themselves a marshal (yes a marshal!) and to enforce the law themselves, then gunfighters battling it out on the streets for control of the town? <br /><br />Nothing even remotely resembling that happened on the Canadian side of the border during the Klondike gold rush. Mr. Mann and company appear to have mistaken Dawson City for Deadwood, the Canadian North for the American Wild West.<br /><br />Canadian viewers be prepared for a Reefer Madness type of enjoyable howl with this ludicrous plot, or, to shake your head in disgust.'\n",
            "label:  0\n",
            "text:  b'This is the kind of film for a snowy Sunday afternoon when the rest of the world can go ahead with its own business as you descend into a big arm-chair and mellow for a couple of hours. Wonderful performances from Cher and Nicolas Cage (as always) gently row the plot along. There are no rapids to cross, no dangerous waters, just a warm and witty paddle through New York life at its best. A family film in every sense and one that deserves the praise it received.'\n",
            "label:  1\n"
          ]
        }
      ],
      "source": [
        "# print to understand the review dataset\n",
        "for example, label in train_dataset.take(4): # check 4 reviews (text and labels)\n",
        "  print('text: ', example.numpy())\n",
        "  print('label: ', label.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9pTxF1xOBxD"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = 10000\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# .shuffle: shuffle the samples to have always a random order of BUFFLE_SIZE samples fed to the network\n",
        "# .batch: batch samples in chunks of size BATCH_SIZE\n",
        "# .prefetch: uses a background thread and an internal buffer to prefetch elements from the input dataset ahead of the time they are requested.\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0B47glW5uwF",
        "outputId": "f408692f-f9d6-4ed9-ae2b-db77a811ed6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "texts:  [b'\"Phantasm\" of 1979 was a highly atmospheric, creepy, scary and very original Horror flick, and, in one word, cult. The first sequel of 1988 was gory, witty, action-packed and highly entertaining. After the first sequel however, \"Phantasm\" creator Don Coscarelly apparently lacked new ideas. \"Phantasm III - Lord Of The Dead\" of 1994 is certainly not a complete failure, it even is quite entertaining, but there is no more originality, and the desperate attempts to bring in something new, are at times tiresome, which makes it quite disappointing in comparison to its predecessors. <br /><br />- SPOILERS - <br /><br />Quite in the beginning, we are introduced the secret behind the mysterious sentinel spheres (the brain-sucking flying silver balls) is unraveled. Thenceforward, a number of unnecessary and annoying new characters (such as Tim, a \"Home Alone\"-style little kid who happens to be great at shooting, an Rocky, a tough and super-cool nunchaku-swinging black chick with a crew cut) are introduced. The film also has its qualities - Reggie Bannister is again very cool as the pony-tailed, guitar playing Reggie. Angus Scrimm is still quite creepy as the Tall Man, but the fact that the Tall Man talks a lot more in this film, makes him loose some of his creepiness. The character of Mike is played by A. Michael Baldwin again (he had been replaced by James LeGros in Part 2), which, in my opinion, doesn\\'t make much of a difference. The gore also keeps the film interesting enough to watch, but it is still a disappointment, especially because the attempts to make up for the lack of ideas get annoying quite quickly.<br /><br />All things considered, \"Phantasm III\" is an acceptable time-waster, but it is definitely disappointing compared to its predecessors. Fans of the first two \"Phantasm\" films can give it a try, but I recommend not to set your expectations too high.'\n",
            " b'Darcy and her young daughter Pamela are heading out to the country where her mum\\'s boyfriend Peter left his doctor\\'s position in the city to become a writer and fix up a bed and breakfast inn. Although this inn has a terrible past and Pamela learns from one the girl\\'s who lives in the town that a deformed witch once reside in that house. They called her the \\'Tooth Fairy\\' as she would kill kids after getting their last baby tooth. This work on the inn, has awoken the \\'Tooth Fairy\\'. Now she has her sights on Pamela and her last baby tooth, but if any gets in the way they face the same fate that awaits Pamela.<br /><br />This flick\\'s old folk myth of the \\'Tooth Fairy\\' doesn\\'t paint her in a very generous way, as you would believe when you were a child. Don\\'t they just love turning happy childhood memories into nightmares! Another one which did fall into the same category was \"Darkness Falls (2003)\". I can\\'t compare how similar they are in the premises, because I haven\\'t seen the latter, but I mostly read they have basically share the same idea. For a little straight to DVD film, this DTV effort looks good and has some promising images surrounding the senseless and traditionally by the book plot device. Low expectations are needed, as I wouldn\\'t class it as an success, but I found it be to marginally entertaining.<br /><br />Cory Strode and Cookie Rae Brown\\'s story or background for this \\'Tooth Fairy\\' character is completely bare with it leaning more towards a slasher vehicle than anything really supernatural. Silly is a good way to describe what\\'s happening in this poorly scripted story, but it never really feels like a fairytale horror. The dialogues can seem rather redundant and morally hounded. While the acting is simply sub-par with the bland characters they have to work off, but director Chuck Bowman offers up some inventive blood splatter and terribly nasty jolts. This kinda makes up for the lack of suspense, the zero scares and generic tone. His direction is reasonably earnest and visually able, where he gets some atmospheric lighting contrasting well with its slick photography. The promising opening scene is creepily effective. His pacing can slow up in parts and there\\'s the odd and unnecessary slow-motion scene put in, but nonetheless it never gets too stodgy with something active occurring which made sure that I wasn\\'t bored.<br /><br />The make-up special effects provided the goods, as there\\'s enough repulsive gruel and the Tooth Fairy\\'s appearance is especially gooey. The figure of the tooth Fairy can look threatening in its black robe, bubbling make-up and swift movements. Being on location helps carve out a more natural feel and can get atmospherically rich in its sense of eeriness. Child actors can be incredibly annoying, but Nicole Mu\\xc3\\xb1oz was decent in her part. Lochlyn Munro and Chandra West are somewhat solid, but can be a little too causal in their performances as Peter and Darcey. The radiantly gorgeous Carrie Anne Fleming is one of their lodgers. P.J Soles shows up in small part as a superstitious neighbour who tries to warn them about the evil that lurks at the inn.<br /><br />I thought it was a okay time-waster that has a sound concept, which just isn\\'t fleshed out enough and the execution is pretty textbook stuff. Watchable nonsense, but at the same time extremely forgettable.'\n",
            " b\"Cybil Richards directs another Full Moon/Surrender Cinema masterpiece of erotica. This time Jacqualine Lovell (dressed in rather fetching silver outfit) is tasked with destroying all evidence of sexual activity. However she can't resist watching the tapes and she kinda likes them. The sex scenes are well filmed and set to a superb soundtrack (at least for this sort of film). The cast are largely awful and mainly very average looking too. Jacqueline Lovell is her exceptionally attractive self and between viewing the sex files she manages to expose her chest and fumble a little down below. She also fits in a little lesbian activity. To be honest Lovell deserves so much better than this kind of fare. Here she looks great naked but actually is much more appealing in her silver attire narrating the 'drama'. Utterly rubbish movie with Lovell and soundtrack the only real redeeming features. Mediocre even for Surrender's output and clearly a new budget low for them also.\"\n",
            " b'This would be a watchable Hollywood mediocre if it had a good editing. It relies on the typical American thriller plot - \"who is going to outsmart everyone\". Acting is below average, but with shining appearance of the detective who is the best actor in the film and he is mostly responsible if the tension in the film rises. Film was completely suffocated by blank video and sound shots and most of it looks like raw film material. All in all, if you don\\'t mind watching a movie that looks like a student film project, this is a film to watch. I guess that would be enough to say on this film, everything else could really spoil the tension that is probably low enough.']\n",
            "\n",
            "labels:  [0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "for example, label in train_dataset.take(1): # after shuffle, print the first batch in train_dataset\n",
        "  print('texts: ', example.numpy()[:4])  # print the first 4 items in the batch\n",
        "  print()\n",
        "  print('labels: ', label.numpy()[:4]) # print the first 4 y values in the batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3xXPU7KOa0Q",
        "outputId": "207837d0-6011-4ffd-8702-534b5ceb78ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['', '[UNK]', 'the', 'and', 'a', 'of', 'to', 'is', 'in', 'it', 'i',\n",
              "       'this', 'that', 'br', 'was', 'as', 'for', 'with', 'movie', 'but',\n",
              "       'film', 'on', 'not', 'you', 'are', 'his', 'have', 'he', 'be',\n",
              "       'one', 'its', 'at', 'all', 'by', 'an', 'they', 'from', 'who', 'so',\n",
              "       'like', 'her', 'just', 'or', 'about', 'has', 'if', 'out', 'some',\n",
              "       'there', 'what', 'good', 'when', 'more', 'very', 'even', 'she',\n",
              "       'my', 'no', 'up', 'would', 'which', 'only', 'time', 'really',\n",
              "       'story', 'their', 'were', 'had', 'see', 'can', 'me', 'than', 'we',\n",
              "       'much', 'well', 'been', 'get', 'will', 'into', 'also', 'because',\n",
              "       'other', 'do', 'people', 'bad', 'great', 'first', 'how', 'most',\n",
              "       'him', 'dont', 'made', 'then', 'movies', 'make', 'films', 'could',\n",
              "       'way', 'them', 'any'], dtype='<U14')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization\n",
        "\n",
        "VOCAB_SIZE = 1000\n",
        "\n",
        "encoder = tf.keras.layers.TextVectorization(max_tokens=VOCAB_SIZE)\n",
        "\n",
        "# call `adapt` on the text-only dataset to create the vocabulary.\n",
        "encoder.adapt(train_dataset.map(lambda text, label: text)) # keep text only, ignore label\n",
        "\n",
        "vocab = np.array(encoder.get_vocabulary())\n",
        "vocab[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxkjYQQyOnaU",
        "outputId": "cd105b80-68aa-4515-ae95-d8b54e9d9156"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([  2,  18,  14, 652,   2, 737,   3,   2,   1,  66,  46,   5,  11,\n",
              "       188,  10,  59, 368,  11,  18])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example = ('The movie was cool. The animation and the graphics '\n",
        "               'were out of this world. I would recommend this movie.')\n",
        "\n",
        "encoded_example = encoder(example)[:20].numpy()  # example is encoded into integers. Print first 20 integers\n",
        "encoded_example # 'the' is encoded to 2, 'movie' is encoded to 18\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fmoj8lFJY7lD",
        "outputId": "505652ef-58a4-494f-e928-9763165888f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([  2,  18,  14,  22,  50,   2, 737,   3,   2,   1,  66, 384,  10,\n",
              "        59,  22, 368,  11,  18])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "example = ('The movie was not good. The animation and the graphics '\n",
        "               'were terrible. I would not recommend this movie.')\n",
        "\n",
        "encoded_example = encoder(example)[:20].numpy()\n",
        "encoded_example  # 'the' is encoded to 2, 'movie' is encoded to 18\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_f5tR7NiO6h_"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    encoder,                                    # pass encoder to the model\n",
        "    tf.keras.layers.Embedding(                  # embedding layer\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=64,\n",
        "        # Use masking to handle the variable sequence lengths\n",
        "        mask_zero=True),                        # embedding layer\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),  # LSTM layer\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),    # LSTM layer\n",
        "    tf.keras.layers.Dense(64, activation='relu'),               # fully connected layer\n",
        "    tf.keras.layers.Dense(1)    # fully connected layer with one output\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWd3kmmAPCap",
        "outputId": "cff92954-8c99-434a-8aed-34d973e5cb65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 6s 6s/step\n",
            "[0.00064196]\n"
          ]
        }
      ],
      "source": [
        "sample_text = ('The movie was cool. The animation and the graphics '\n",
        "               'were out of this world. I would recommend this movie.')\n",
        "predictions = model.predict(np.array([sample_text]))\n",
        "print(predictions[0])  # you can see the output/label is random, because we have not trained the LSTM model yet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-mi5OJ3POYL",
        "outputId": "5a2ed8d3-d276-4d86-f118-c4267c0ce8dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "391/391 [==============================] - 1525s 4s/step - loss: 0.5749 - accuracy: 0.6382 - val_loss: 0.4110 - val_accuracy: 0.7969\n",
            "Epoch 2/3\n",
            "391/391 [==============================] - 1510s 4s/step - loss: 0.3540 - accuracy: 0.8429 - val_loss: 0.3435 - val_accuracy: 0.8510\n",
            "Epoch 3/3\n",
            "391/391 [==============================] - 1491s 4s/step - loss: 0.3204 - accuracy: 0.8618 - val_loss: 0.3242 - val_accuracy: 0.8589\n"
          ]
        }
      ],
      "source": [
        "# choose loss function, optimizer, and performance metrics:\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# train the model:\n",
        "history = model.fit(train_dataset, epochs=3,\n",
        "                    validation_data=test_dataset,\n",
        "                    validation_steps=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouoLuGLEQmdN",
        "outputId": "52d374eb-bdfd-4b64-c980-7887135eccb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 189ms/step\n",
            "[[-0.00651081]]\n"
          ]
        }
      ],
      "source": [
        "# predict on a sample text without padding.\n",
        "\n",
        "sample_text = ('The movie was not good. The animation and the graphics '\n",
        "               'were terrible. I would not recommend this movie.')\n",
        "\n",
        "predictions = model.predict(np.array([sample_text]))\n",
        "print(predictions)\n",
        "\n",
        "sample_text = ('The movie was cool. The animation and the graphics '\n",
        "               'were out of this world. I would recommend this movie.')\n",
        "\n",
        "predictions = model.predict(np.array([sample_text]))\n",
        "print(predictions)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}